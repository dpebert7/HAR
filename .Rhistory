library(e1071)
model = naiveBayes(Class~., data = HouseVotes84)
data(HouseVotes84)
library("mlbench")
install.packages("mlbench")
library("mlbench")
data(HouseVotes84)
model = naiveBayes(Class~., data = HouseVotes84)
model$apriori
table(HouseVotes84$Class)
predict(model, newdata = HouseVotes84[1,], type = "raw")
predict(model, newdata = HouseVotes84[1,], type = "class")
predict(model, newdata = HouseVotes84[1,])
predict(model, newdata = HouseVotes84[1:5,])
predict(model, newdata = HouseVotes84[1:5,], type = "raw")
predict(model, newdata = HouseVotes84[1:5,], type = "class")
predict(model, newdata = HouseVotes84, type = "class")
predict(model, newdata = HouseVotes84, type = "raw")
predict(model, newdata = HouseVotes84)
bin.HARsvm = svm(bin.y_train~., data = X_train, kernel = "linear", cost = 1000)
library(e1071)
# Begin by importing X_test, X_train, y_test, and y_train from the UCI repository.
# http://archive.ics.uci.edu/ml/machine-learning-databases/00240/
# UCI HAR Dataset.zips
###############################
# Case 1: basic SVM in 2-case #
###############################
#Fit SVM model to training data
bin.HARsvm = svm(bin.y_train~., data = X_train, kernel = "linear", cost = 1000)
bin.train.SVM.HAR.pred = predict(bin.HARsvm, newdata = X_train)
confmatrix(bin.y_train, train.SVM.HAR.pred)
bin.test.SVM.HAR.pred = predict(bin.HARsvm, newdata = X_test)
confmatrix(bin.y_test, test.SVM.HAR.pred)
# 100% Accuracy. Linearly Separable. Yay!
plot(X_train$V390, col = bin.y_train)
plot(X_train$V390, col = y_train)
plot(X_train$V390, col = y_train$V1)
